{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\v}[1]{\\textbf{#1}}\n",
    "\\newcommand{\\T}{^\\top}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator{\\Tr}{Tr}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$\n",
    "    HMM = \\left\\{ \n",
    "        S, O, A_0 \\in [0,1]^S, A \\in [0,1]^{S \\times S}, Q \\in [0,1]^{S \\times O} \n",
    "    \\right\\}\n",
    "$$\n",
    "---\n",
    "### Three Main Problems\n",
    "\n",
    "<h4> 1. Likelihood: &emsp; $\\Pr(o_1, ..., o_T) = ?$ \n",
    "</h4>\n",
    "\n",
    "<h4> 2. Decoding (state prediction): &emsp;  $\\argmax_{\\v s} \\left\\{ \\Pr( \\v o \\mid \\v s) \\right\\} \\quad$ where $\\v o, \\v s \\in \\R^T$\n",
    "</h4>\n",
    "\n",
    "<h4> 3. Learning: &emsp;  Infer $(A, Q)$ &ensp; given a training set &ensp; $\\{\\v o^{(i)}\\}_{i=1..N}$\n",
    "</h4>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we are at a casino, and the dealer switches to a positively biased coin with probability $0.1$ and a negatively biased coin with probability $0.1$.\n",
    "Every turn, sher returns to the fair coin with probability .2, and remains with the biased w.p. .8.\n",
    "\n",
    "The biased coins are 60-40 / 40-60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 0 2 0]\n",
      "[0 0 0 0 0 0 0 1 1 1]\n",
      "[0.33 0.8  0.8  0.8  0.8  0.8  0.2  0.4  0.3  0.2 ]\n",
      "[0.95 0.95 0.95 0.95 0.95 0.95 0.5  0.5  0.95 0.5 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.57662330368e-05"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM:\n",
    "    \n",
    "    def __init__(self, A_0, A, Q):\n",
    "        self.A_0 = A_0\n",
    "        self.A = A\n",
    "        self.Q = Q\n",
    "        \n",
    "    def pr_state_trans(self, s_seq):\n",
    "        T = len(s_seq)\n",
    "        s_tran_probs = np.zeros(T)\n",
    "        s_tran_probs[0] = self.A_0[s_seq[0]]\n",
    "        s_tran_probs[1:] = self.A[s_seq[:-1], s_seq[1:]]\n",
    "        return s_tran_probs\n",
    "\n",
    "    def pr_emissions(self, o_seq, s_seq):\n",
    "        return self.Q[s_seq, o_seq]\n",
    "    \n",
    "    def pr_obs(self, o_seq, s_seq):\n",
    "        s_tran_probs = self.pr_state_trans(s_seq)\n",
    "        emission_probs = self.pr_emissions(o_seq, s_seq)\n",
    "        return s_tran_probs.prod() * emission_probs.prod()\n",
    "        \n",
    "def gen_HMM(p_bias=.95):\n",
    "    A = np.array([\n",
    "        [.4, .3, .3],\n",
    "        [.2, .8, 0],\n",
    "        [.2, 0, .8]\n",
    "    ])\n",
    "    A_0 = np.ones(3)/3.\n",
    "    Q = np.array([\n",
    "        [.5, .5],\n",
    "        [p_bias, 1 - p_bias],\n",
    "        [1-p_bias, p_bias]\n",
    "    ])\n",
    "    return HMM(A_0, A, Q)\n",
    "\n",
    "def sample_obs_seq(hmm, T=10):\n",
    "    A_0, A, Q = hmm.A_0, hmm.A, hmm.Q\n",
    "    \n",
    "    def sample_multinoulli(probs):\n",
    "        return np.argmax(np.random.multinomial(1, probs))\n",
    "\n",
    "    s_seq = np.ones(T, dtype=int)*-1\n",
    "    o_seq = np.ones(T, dtype=int)*-1\n",
    "    s_seq[0] = sample_multinoulli(hmm.A_0)\n",
    "    for t in range(T):\n",
    "        curr_s = s_seq[t]\n",
    "        o_seq[t] = sample_multinoulli(hmm.Q[curr_s])\n",
    "        if t < T-1:\n",
    "            next_s = sample_multinoulli(hmm.A[curr_s])\n",
    "            s_seq[t+1] = next_s\n",
    "\n",
    "    return o_seq, s_seq\n",
    "\n",
    "hmm = gen_HMM(p_bias=.95)\n",
    "\n",
    "o_seq, s_seq = sample_obs_seq(hmm, T=10)\n",
    "np.set_printoptions(linewidth=200, precision=2)\n",
    "print(s_seq)\n",
    "print(o_seq)\n",
    "print(hmm.pr_state_trans(s_seq))\n",
    "print(hmm.pr_emissions(o_seq, s_seq))\n",
    "hmm.pr_obs(o_seq, s_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\n",
    "\\Pr(\\v s) \n",
    "    = \\Pr(s_1) \\prod_{t=2}^T \\Pr(s_t \\mid s_{t-1})\n",
    "    = A_0[s_1] \\prod_{t=2}^T A[s_{t-1}, s_t]\n",
    "$\n",
    "\n",
    "\n",
    "* $\n",
    "\\Pr(\\v o \\mid \\v s) \n",
    "    = \\prod_{t=1}^T \\Pr(o_t \\mid s_t)\n",
    "    = \\prod_{t=1}^T Q[s_t, o_t]\n",
    "$\n",
    "\n",
    "* $\n",
    "\\Pr(\\v o) = \\Pr(o_1, ..., o_T) = \\sum_{\\v s \\in S^T} \\Pr(\\v o \\mid \\v s)\\Pr(\\v s)\n",
    "$\n",
    "\n",
    "* If $x\\in \\Delta_S$ is the current state distribution $ x\\T A $ gives the next state distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Forward Algorithm\n",
    "\n",
    "* <b>Initialization:</b> \n",
    "\n",
    "&emsp; &emsp; $\n",
    "    \\Pr(s_1 = s \\wedge o_1 ) = A_0[s] Q[s, o_1]\n",
    "$\n",
    "\n",
    "* <b>Recursion</b>: \n",
    "\n",
    "&emsp; &emsp; $ \n",
    "\\Pr(s_t = s' \\wedge o_1,..,o_t) \n",
    "    = \\sum_{s \\in S} \\Pr(s_{t-1}=s \\wedge o_1,..,o_{t-1}) \\Pr(s \\mid s') \\Pr(o_t \\mid s')\n",
    "$\n",
    "\n",
    "&emsp; &emsp; $ \n",
    "F[t, s'] \n",
    "    = \\sum_{s \\in S} F[t-1, s] A[s, s'] Q[s', o_t]\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "[1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "o_seq, s_seq = sample_obs_seq(hmm, T=30)\n",
    "\n",
    "print(s_seq)\n",
    "print(o_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1117751440035405e-06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(o_seq, hmm):\n",
    "    A_0, A, Q = hmm.A_0, hmm.A, hmm.Q\n",
    "    T = len(o_seq)\n",
    "    N_s, N_o = Q.shape\n",
    "\n",
    "    F = np.zeros([T, N_s])\n",
    "\n",
    "    # Initialization\n",
    "    F[0, :] = A_0 * Q[range(N_s), o_seq[0]]\n",
    "    \n",
    "    # DP\n",
    "    for t in range(1, T):\n",
    "        o_t = o_seq[t]\n",
    "        for s_next in range(N_s):\n",
    "            q = F[t-1] * A[:, s_next] * Q[s_next, o_t]\n",
    "            F[t, s_next] = q.sum()\n",
    "\n",
    "    return F[T-1].sum()\n",
    "    \n",
    "forward(o_seq, hmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Viterbi Algorithm\n",
    "\n",
    "* <b>Initialization:</b> \n",
    "\n",
    "&emsp; &emsp; $\n",
    "    F[0, s] = A_0[s] Q[s, o_1]\n",
    "$\n",
    "\n",
    "&emsp; &emsp; $\n",
    "    Bp[0, s] = -1\n",
    "$\n",
    "\n",
    "* <b>Recursion</b>: \n",
    "\n",
    "&emsp; &emsp; $ \n",
    "    F[t, s'] = \\max_{s \\in S} \\{ F[t-1, s] A[s, s'] Q[s', o_t] \\}\n",
    "$\n",
    "\n",
    "&emsp; &emsp; $ \n",
    "    Bp[t, s'] = \\argmax_{s \\in S} \\{\"\\}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: [0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "TRUE: [2 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "OBS : [1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def viterbi(o_seq, hmm):\n",
    "    A_0, A, Q = hmm.A_0, hmm.A, hmm.Q\n",
    "    T = len(o_seq)\n",
    "    N_s, N_o = Q.shape\n",
    "\n",
    "    F = np.zeros([T, N_s])\n",
    "    Bp = np.zeros([T, N_s], dtype=int)\n",
    "    \n",
    "    # Initialization\n",
    "    F[0, :] = A_0 * Q[range(N_s), o_seq[0]]\n",
    "    Bp[0, :] = -1\n",
    "    \n",
    "    # DP\n",
    "    for t in range(1, T):\n",
    "        o_t = o_seq[t]\n",
    "        for s_next in range(N_s):\n",
    "            q = F[t-1] * A[:, s_next] * Q[s_next, o_t]\n",
    "            Bp[t, s_next] = q.argmax()\n",
    "            F[t, s_next] = q.max()\n",
    "    \n",
    "    best_path = [F[T-1].argmax()]\n",
    "    for t in range(T-1, 0, -1):\n",
    "        s_prev = Bp[t, best_path[-1]]\n",
    "        best_path.append(s_prev)\n",
    "    best_path = np.flip(best_path)\n",
    "    \n",
    "    max_prob = F[T-1].max()\n",
    "    return F, Bp, best_path, max_prob\n",
    "\n",
    "F, Bp, best_path, max_prob = viterbi(o_seq, hmm)\n",
    "\n",
    "print(f'PRED: {best_path}')\n",
    "print(f'TRUE: {s_seq}')\n",
    "print(f'OBS : {o_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curriculum_vqa",
   "language": "python",
   "name": "curriculum_vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
