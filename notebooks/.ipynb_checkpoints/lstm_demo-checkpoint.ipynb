{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 3, 32])\n",
      "torch.Size([2, 3, 32])\n",
      "torch.Size([2, 3, 32])\n"
     ]
    }
   ],
   "source": [
    "L, d_model, d_h = 2, 16, 32\n",
    "\n",
    "lstm = nn.LSTM(input_size=d_model, hidden_size=d_h, num_layers=L)\n",
    "\n",
    "N_seq, B = 9, 3\n",
    "\n",
    "X = torch.rand(N_seq, B, d_model)\n",
    "h_0 = torch.zeros(L, B, d_h)\n",
    "c_0 = torch.zeros(L, B, d_h)\n",
    "\n",
    "out, (h_n, c_n) = lstm(X, (h_0, c_0))\n",
    "\n",
    "print(out.shape)\n",
    "print(h_n.shape)\n",
    "print(c_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_X, vocab_Y, d_input=16, d_target=16, d_h=16, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.vocab_X = vocab_X\n",
    "        self.vocab_Y = vocab_Y\n",
    "        self.d_h = d_h\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.E_input = nn.Embedding(vocab_X.N_tokens, d_input)\n",
    "        self.encoder_lstm = nn.LSTM(d_input, d_h, num_layers=num_layers)\n",
    "        self.decoder_lstm = nn.LSTM(d_target, d_h, num_layers=num_layers)\n",
    "        self.W_o = nn.Linear(d_h, d_target)\n",
    "        self.E_target = nn.Embedding(vocab_Y.N_tokens, d_target)\n",
    "\n",
    "    def init_hiddens(self, B):\n",
    "        h_0 = torch.zeros(self.num_layers, B, self.d_h)\n",
    "        c_0 = torch.zeros(self.num_layers, B, self.d_h)\n",
    "        return h_0, c_0\n",
    "\n",
    "    def forward(self, X, decoder_input, decoder_hidden_state=None):\n",
    "        \"\"\"\n",
    "        X: [B, N_seq]\n",
    "        target: [B, N_seq_t]\n",
    "\n",
    "        returns logits for target tokens: [B, N_seq_t, V_target]\n",
    "        \"\"\"\n",
    "        B, N_seq = X.shape\n",
    "        if decoder_hidden_state is None:\n",
    "            X_embed = self.E_input(X)\n",
    "            X_embed = X_embed.transpose(0, 1)  # [N_seq, B, d_input]\n",
    "\n",
    "            h_0, c_0 = self.init_hiddens(B)\n",
    "            encoder_out, (enc_h_n, enc_c_n) = self.encoder_lstm(X_embed, (h_0, c_0))\n",
    "            decoder_hidden_state = (enc_h_n, enc_c_n)\n",
    "\n",
    "        target_embed = self.E_target(decoder_input)\n",
    "        target_embed = target_embed.transpose(0, 1)\n",
    "        decoder_out, decoder_hidden_state = self.decoder_lstm(target_embed, decoder_hidden_state)\n",
    "\n",
    "        # decoder_out: [N_seq_t, B, d_h]\n",
    "        decoder_out = decoder_out.transpose(0, 1)\n",
    "        pred_target_vecs = self.W_o(decoder_out)\n",
    "        logits = F.linear(pred_target_vecs, self.E_target.weight)\n",
    "\n",
    "        return logits, decoder_hidden_state\n",
    "\n",
    "\n",
    "def autoregressive_decode(X, model, bos, eos, max_len=20):\n",
    "    B, N_seq = X.shape\n",
    "    bos_tokens = torch.ones(B, 1, dtype=torch.long) * bos\n",
    "    y_pred = [bos_tokens]\n",
    "    logits = []\n",
    "    decode_state = None\n",
    "    for t in range(max_len):\n",
    "        y_next_logit, decode_state = model(X, y_pred[-1], decode_state)\n",
    "        _, y_next_token = torch.max(y_next_logit, axis=-1)\n",
    "        logits.append(y_next_logit)\n",
    "        y_pred.append(y_next_token)\n",
    "        if y_next_token == eos:\n",
    "            break\n",
    "\n",
    "    return torch.cat(logits, dim=1), torch.cat(y_pred[1:], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \n",
    "    def __init__(self, d_embed=16):\n",
    "        self.unk = 0\n",
    "        self.pad = 1\n",
    "        self.bos = 2\n",
    "        self.eos = 3\n",
    "        self.tokens = {\n",
    "            '<unk>': self.unk,\n",
    "            '<pad>': self.pad,\n",
    "            '<s>': self.bos,\n",
    "            '</s>': self.eos,\n",
    "        }\n",
    "        self.idxs = None\n",
    "        self.building = True\n",
    "        self.d_embed = d_embed\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def build(self):\n",
    "        self.building = False\n",
    "        self.idxs = {v: k for k, v in self.tokens.items()}\n",
    "        self.N_tokens = len(self)\n",
    "        \n",
    "    def encode(self, tokens):\n",
    "        ret = []\n",
    "        for t in tokens:\n",
    "            ret.append(self.encode_symbol(t))\n",
    "        return ret\n",
    "    \n",
    "    def encode_symbol(self, token):\n",
    "        ret = self.tokens.get(token, self.unk)\n",
    "        if ret == self.unk and self.building:\n",
    "            ret = len(self.tokens)\n",
    "            self.tokens[token] = ret\n",
    "        return ret\n",
    "    \n",
    "    def all_tokens(self):\n",
    "        return list(self.tokens.keys())[3:]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        if type(tokens) == torch.Tensor:\n",
    "            tokens = list(tokens.numpy().squeeze())\n",
    "        if type(tokens) == np.ndarray:\n",
    "            tokens = list(tokens.squeeze())\n",
    "            \n",
    "        if type(tokens) == list:\n",
    "            return [self.idxs[t] for t in tokens]\n",
    "        else:\n",
    "            return self.idxs[tokens[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sentences(characters, N_samples=1000, sentence_len=5, N_words=100, word_len=4):\n",
    "    \n",
    "    vocab = Vocabulary()\n",
    "    \n",
    "    for i in range(N_words):\n",
    "        w = ''.join(random.choices(characters, k=word_len))\n",
    "        vocab.encode_symbol(w)\n",
    "    \n",
    "    vocab.build()\n",
    "    words = vocab.all_tokens()\n",
    "    samples = []\n",
    "    samples_txt = []\n",
    "    for i in range(N_samples):\n",
    "        s = random.choices(words, k=sentence_len)\n",
    "        samples_txt.append(' '.join(s))\n",
    "        samples.append([vocab.bos] + vocab.encode(s) + [vocab.eos])\n",
    "    \n",
    "    return torch.tensor(samples), vocab, samples_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.006429367698729038: 100%|██████████| 500/500 [00:03<00:00, 125.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X_all, vocab_X, X_txt = random_sentences('abcdefghijklmnop', N_samples=10, sentence_len=5, N_words=100, word_len=4)\n",
    "Y_all, vocab_Y, Y_txt = random_sentences('ABCDEFGHIJKLMNOP', N_samples=10, sentence_len=5, N_words=100, word_len=4)\n",
    "\n",
    "\n",
    "model = Seq2SeqLSTM(vocab_X, vocab_Y, d_h=16, num_layers=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = []\n",
    "with tqdm(range(500)) as pbar:\n",
    "    for i in pbar:\n",
    "        batch_idxs = torch.randint(len(X_all), [32])\n",
    "        X_batch = X_all[batch_idxs]\n",
    "        Y_batch = Y_all[batch_idxs]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        Y_logits, _ = model(X_batch, Y_batch)\n",
    "\n",
    "        loss = loss_fn(Y_logits.flatten(end_dim=1)[:-1], Y_batch.flatten()[1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        if i % 100 == 0:\n",
    "            pbar.set_description(f'Loss={loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[89, 30, 82, 25, 22,  3]])\n",
      "tensor([[89, 30, 82, 25, 22,  3]])\n"
     ]
    }
   ],
   "source": [
    "logits, _ = model(X_all[[0]], Y_all[[0]])\n",
    "_, y_pred = torch.max(logits, axis=-1)\n",
    "print(y_pred[:, :-1])\n",
    "\n",
    "logits, y_pred = autoregressive_decode(X_all[[0]], model, vocab_X.bos, vocab_X.eos)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curriculum_vqa",
   "language": "python",
   "name": "curriculum_vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
