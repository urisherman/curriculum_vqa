{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "_include_('curriculum_vqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEVR_root = f'{DEV_HOME}/curriculum_vqa/data-bin/CLEVR_v1.0'\n",
    "CLEVR_fil_root = f'{DEV_HOME}/curriculum_vqa/data-bin/CLEVR_small_6'\n",
    "CLEVR_mini_root = f'{DEV_HOME}/curriculum_vqa/data-bin/CLEVR_mini_6'\n",
    "\n",
    "# ds = datasets.CLEVR(CLEVR_root, split='val')\n",
    "# len(x['program']) < 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def filter_dataset(split, target_root, predicate_fn, subsample=None):\n",
    "#     with open(f'{CLEVR_root}/scenes/CLEVR_{split}_scenes.json') as f:\n",
    "#         scenes = json.load(f)['scenes']\n",
    "        \n",
    "    with open(f'{CLEVR_root}/questions/CLEVR_{split}_questions.json') as f:\n",
    "        questions = json.load(f)['questions']\n",
    "    \n",
    "    print(f'Loaded {len(questions)} questions.')\n",
    "    filtered_questions = [x for x in questions if predicate_fn(x) ]\n",
    "    print(f'We have {len(filtered_questions)} questions after filtering.')\n",
    "    if subsample is not None:\n",
    "        filtered_questions = random.choices(filtered_questions, k=subsample)\n",
    "        print(f'We have {len(filtered_questions)} questions after sub-sampling.')\n",
    "        \n",
    "    os.makedirs(f'{target_root}/questions', exist_ok=True)\n",
    "\n",
    "    with open(f'{target_root}/questions/CLEVR_{split}_questions.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'info': 'Filtered',\n",
    "            'questions': filtered_questions\n",
    "        }, f)\n",
    "        \n",
    "    os.makedirs(f'{target_root}/scenes', exist_ok=True)\n",
    "\n",
    "    shutil.copy(f'{CLEVR_root}/scenes/CLEVR_{split}_scenes.json', f'{target_root}/scenes/CLEVR_{split}_scenes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 699989 questions.\n",
      "We have 46258 questions after filtering.\n",
      "We have 3000 questions after sub-sampling.\n",
      "Loaded 149991 questions.\n",
      "We have 9887 questions after filtering.\n",
      "We have 600 questions after sub-sampling.\n"
     ]
    }
   ],
   "source": [
    "filter_dataset('train', CLEVR_mini_root, lambda x: len(x['program']) < 6, subsample=3000)\n",
    "filter_dataset('val', CLEVR_mini_root, lambda x: len(x['program']) < 6, subsample=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_dataset('train', CLEVR_fil_root, lambda x: len(x['program']) < 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(map(lambda x: x['question'], filtered_questions))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{CLEVR_root}/questions/CLEVR_val_questions.json') as f:\n",
    "        questions = json.load(f)['questions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21229"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate_fn = lambda x: len(x['program']) < 7\n",
    "filtered_questions = [x for x in questions if predicate_fn(x) ]\n",
    "len(filtered_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_index': 29,\n",
       " 'program': [{'inputs': [], 'function': 'scene', 'value_inputs': []},\n",
       "  {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['small']},\n",
       "  {'inputs': [1], 'function': 'filter_material', 'value_inputs': ['metal']},\n",
       "  {'inputs': [2], 'function': 'unique', 'value_inputs': []},\n",
       "  {'inputs': [3], 'function': 'same_shape', 'value_inputs': []},\n",
       "  {'inputs': [4], 'function': 'count', 'value_inputs': []}],\n",
       " 'question_index': 291,\n",
       " 'image_filename': 'CLEVR_val_000029.png',\n",
       " 'question_family_index': 43,\n",
       " 'split': 'val',\n",
       " 'answer': '1',\n",
       " 'question': 'How many other objects are the same shape as the tiny metal thing?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_short = filtered_questions[44]\n",
    "program_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "    \n",
    "def tokenize_program(prog_str):\n",
    "    return [x for x in re.compile('([\\(\\).,\\s])').split(prog_str) if x.strip() != '']\n",
    "\n",
    "def build_prog_str(prog):\n",
    "    answer_op = prog[-1]\n",
    "    answer_op_inputs = []\n",
    "    for i in answer_op['inputs']:\n",
    "        # generate obj pipeline by rolling backwards\n",
    "        pipe = []\n",
    "        curr_line = prog[i]\n",
    "        while True:\n",
    "            func_args = curr_line[\"value_inputs\"]\n",
    "            if len(func_args) > 0:\n",
    "                func_args = f\"'{func_args[0]}'\"\n",
    "            else:\n",
    "                func_args = ''\n",
    "            pipe.append(curr_line['function'] + f'({func_args})')\n",
    "            if len(curr_line['inputs']) == 0:\n",
    "                break\n",
    "            else:\n",
    "                curr_line = prog[curr_line['inputs'][0]]\n",
    "        answer_op_inputs.append('.'.join(pipe[::-1]))\n",
    "\n",
    "    output = answer_op['function'] + '(' + ', '.join(answer_op_inputs) + ')'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"count(scene().filter_size('small').filter_material('metal').unique().same_shape())\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = program_short['program']\n",
    "\n",
    "prog_str = build_prog_str(prog)\n",
    "prog_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"count(scene().filter_size('small').filter_material('metal').unique().same_shape())\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tokenize_program(prog_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curriculum_vqa",
   "language": "python",
   "name": "curriculum_vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
