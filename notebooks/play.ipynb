{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "_include_('curriculum_vqa')\n",
    "_include_('commons')\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed);\n",
    "\n",
    "from cvqa import datasets, models, trainers, viz\n",
    "from commons import debug\n",
    "\n",
    "data_bin = f'{DEV_HOME}/curriculum_vqa/data-bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4575, 0.0321, 0.7627, 0.4869, 0.2839, 0.9829, 0.8800],\n",
       "        [0.5833, 0.1697, 0.8943, 0.0018, 0.5963, 0.5486, 0.9592],\n",
       "        [0.0822, 0.7958, 0.6468, 0.6121, 0.8299, 0.7273, 0.0548],\n",
       "        [0.4219, 0.3685, 0.0146, 0.2408, 0.4143, 0.6273, 0.8278],\n",
       "        [0.4315, 0.2955, 0.0548, 0.4291, 0.1078, 0.9327, 0.8081]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([\n",
    "    torch.rand(5, 2),\n",
    "    torch.rand(5, 5),\n",
    "], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model Specification\n",
    "\n",
    "Concepts (red, block, triangle)\n",
    "* $c \\in [C]$ denotes a Concept Symbol\n",
    "* $v_c \\in \\mathbb R^{d_c}$ a concept vector\n",
    "* $E_c \\in \\mathbb R^{d_c \\times C}$ the concepts embedding matrix\n",
    "\n",
    "Concept Categories (shape, color)\n",
    "* $k \\in [K]$ denotes a Concept Category (color, shape)\n",
    "* $v_k \\in \\mathbb R^{d_k}$ a concept category vector\n",
    "* $E_k \\in \\mathbb R^{d_k \\times K}$ the concept categories embedding matrix\n",
    "\n",
    "Relations (contains, below, above)\n",
    "* $r \\in [R]$ denotes a relational concept Symbol\n",
    "* $v_r \\in \\mathbb R^{d_r}$ a concept vector\n",
    "* $E_r \\in \\mathbb R^{d_r \\times R}$ the relations embedding matrix\n",
    "\n",
    "\n",
    "\n",
    "Others\n",
    "* $o \\in \\mathbb R^{d_o}$ denotes a visual object.\n",
    "* $Q \\in \\mathbb R^{d_o \\times d_c \\times d_k}$ - The concept operators matrix.\n",
    "\n",
    "\n",
    "$ W_k = Q^\\top v_k $\n",
    "\n",
    "$k(o) = softmax(o^\\top W_k)$  // Gives the concept distribution for category k (eg color) of object o (eg the 3rd object in the scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "C = 100\n",
    "\n",
    "B = 32\n",
    "\n",
    "d = {\n",
    "    'B': 32,\n",
    "    \n",
    "    'o': 16,\n",
    "    'c': 40,\n",
    "    'k': 4,\n",
    "    'r': 25,\n",
    "    'ak': 29,\n",
    "    'av': 21,\n",
    "    \n",
    "    'w': 44,\n",
    "    'a': 45,\n",
    "    \n",
    "    'N_o': 7,\n",
    "    'N_p': 3\n",
    "}\n",
    "\n",
    "d_reversed = {v: k for k, v in d.items()}\n",
    "def shape(t):\n",
    "    return list(map(lambda dim: d_reversed.get(dim, dim), t.shape))\n",
    "    \n",
    "# shape(torch.rand(d['c'], d['o']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_c = torch.rand(C, d['c'])\n",
    "W_kc = torch.rand(d['k'], d['c'])\n",
    "\n",
    "C_ops = torch.rand(d['o'], d['c'], d['k'])\n",
    "Q_ops = torch.rand(d['o'], d['a'], d['k'])\n",
    "\n",
    "N_o = 7\n",
    "N_p = 3\n",
    "X = torch.rand(B, N_o, d['o'])\n",
    "X_weights_in_1 = torch.ones(d['B'], d['N_o'])\n",
    "X_weights_in_2 = torch.ones(d['B'], d['N_o'])\n",
    "X_weights_in = X_weights_in_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_op(op_seed, op_mat):\n",
    "    \"\"\"\n",
    "    op_seed: [B, d_op]\n",
    "    op_mat: [d_in, d_out, d_op]\n",
    "    \"\"\"\n",
    "    d_in, d_out, d_op = op_mat.shape\n",
    "    W = F.linear(op_seed, op_mat.reshape(-1, d_op))  # [B, d_out * d_in]\n",
    "    \n",
    "    return W.reshape(B, d_in, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_op = torch.rand(B, d['k'])\n",
    "\n",
    "# W_answer = get_op(question_op, Q_ops)  # [B, o, a]\n",
    "    \n",
    "# weighted_X = torch.matmul(X_weights_in.unsqueeze(1), X).squeeze()  # [B, o]\n",
    "\n",
    "# logits = torch.matmul(weighted_X.unsqueeze(1), W_answer)\n",
    "# shape(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_module(X, X_weights_in, question_op):\n",
    "    \"\"\"\n",
    "    X: [B, N_o, d_o]\n",
    "    X_weights_in: [B, N_o]\n",
    "    question_op: [B, d_k]\n",
    "    \"\"\"\n",
    "    W_answer = get_op(question_op, Q_ops)  # [o, a]\n",
    "    \n",
    "    weighted_X = torch.matmul(X_weights_in.unsqueeze(1), X).squeeze()  # [B, o]\n",
    "    \n",
    "    logits = torch.matmul(weighted_X.unsqueeze(1), W_answer)\n",
    "    return logits.squeeze()\n",
    "    \n",
    "shape(answer_module(X, X_weights_in_1, torch.rand(B, d['k'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'N_o']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1_module(X, X_weights_in, op):\n",
    "    \"\"\"\n",
    "    X: [B, N_o, d_o]\n",
    "    X_weights_in: [B, N_o]\n",
    "    op: [B, d_c]\n",
    "    \"\"\"\n",
    "    \n",
    "    #### Concept Category Predicate\n",
    "\n",
    "    # 1) op seed --> batch of concept ops\n",
    "    P = op  # P for predicate \n",
    "    P_k = F.linear(P, W_kc)  # [B, d_k] P_k for predicate category (eg color)\n",
    "    P_k = get_op(P_k, C_ops)  # [B, d_o, d_c]\n",
    "\n",
    "    # 2) Apply derived concept op to each object\n",
    "    X_c = torch.matmul(torch.rand(B, N_o, d['o']), P_k)  # [B, N_o, d_c]\n",
    "\n",
    "    # 3) Compute cosine similarity in concept distribution space (is there a better way to do this?)\n",
    "    X_c_probs = F.softmax(torch.matmul(X_c, E_c.T), dim=-1) # [B, N_o, C]\n",
    "    P_c_probs = F.softmax(torch.matmul(P, E_c.T), dim=-1) # [B, C]\n",
    "    XP_res = torch.sum(X_c_probs * P_c_probs.unsqueeze(1), dim=-1)  # [B, N_o], holds the probability every object passes the predicate\n",
    "\n",
    "    \n",
    "    #### Logical Not? Other Structures?\n",
    "    return X_weights_in * XP_res\n",
    "\n",
    "op1 = torch.rand(B, d['c'])\n",
    "f1_res = f1_module(X, X_weights_in_1, op1)\n",
    "shape(f1_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def attention(query, key, value, mask_weights=None, dropout=None):\n",
    "    \"\"\"\n",
    "    Copied and adjusted from the annotated transformer; https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask_weights is not None:\n",
    "        scores += mask_weights.unsqueeze(1).log()\n",
    "        \n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ops_q = torch.rand(d['o'], d['ak'], d['r'])\n",
    "A_ops_k = torch.rand(d['o'], d['ak'], d['r'])\n",
    "A_ops_v = torch.rand(d['o'], d['av'], d['r'])\n",
    "\n",
    "A_W_res = torch.rand(d['av'], 2)\n",
    "\n",
    "# rel_op = torch.rand(B, d['r'])\n",
    "# W_q = get_op(rel_op, A_ops_q)\n",
    "# W_k = get_op(rel_op, A_ops_k)\n",
    "# W_v = get_op(rel_op, A_ops_v)\n",
    "\n",
    "\n",
    "# Q = torch.matmul(X, W_q)\n",
    "# K = torch.matmul(X, W_k)\n",
    "# V = torch.matmul(X, W_v)\n",
    "\n",
    "# X_weights_in_1 = torch.ones(d['B'], d['N_o'])\n",
    "# X_weights_in_2 = torch.ones(d['B'], d['N_o'])\n",
    "\n",
    "# shape(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# att_res, p_att = attention(Q, K, V, X_weights_in_2)\n",
    "\n",
    "# shape(att_res)\n",
    "\n",
    "# res = F.softmax(F.linear(att_res, A_W_res.T), dim=-1)\n",
    "# shape(res[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'N_o']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f2_module(X, X_weights_in_1, X_weights_in_2, rel_op):\n",
    "    \"\"\"\n",
    "    X: [B, N_o, d_o]\n",
    "    X_weights_in_1, X_weights_in_2: [B, N_o]\n",
    "    rel_op: [B, d_r]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) op seed --> batch of attention parameters matrices\n",
    "    W_q = get_op(rel_op, A_ops_q)\n",
    "    W_k = get_op(rel_op, A_ops_k)\n",
    "    W_v = get_op(rel_op, A_ops_v)\n",
    "\n",
    "    Q = torch.matmul(X, W_q)\n",
    "    K = torch.matmul(X, W_k)\n",
    "    V = torch.matmul(X, W_v)\n",
    "    \n",
    "#     Q = Q * X_weights_in_1\n",
    "    \n",
    "    att_res, p_att = attention(Q, K, V, X_weights_in_2)\n",
    "    res = F.softmax(F.linear(att_res, A_W_res.T), dim=-1)\n",
    "    return res[:, :, 0] * X_weights_in_1\n",
    "\n",
    "\n",
    "\n",
    "rel_op = torch.rand(B, d['r'])\n",
    "\n",
    "f2_res = f2_module(X, X_weights_in_1, X_weights_in_2, rel_op)\n",
    "shape(f2_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate = torch.rand(B, N_p, d_c)\n",
    "\n",
    "\n",
    "# def apply_predicate(X, P):\n",
    "#     # objects concepts index\n",
    "#     X_ck = torch.matmul(X.unsqueeze(1), Q)  # [B, d_c, N_o, d_k]\n",
    "#     X_ck = X_ck.transpose(1, 2) # [B, N_o, d_c, d_k]\n",
    "\n",
    "#     # predicate to categories\n",
    "#     P_k = F.linear(P, W_kc)  # [B, N_p, d_k]\n",
    "#     P_k = P_k.transpose(1, 2)  # [B, d_k, N_p]\n",
    "\n",
    "#     # [B, N_o, d_c, d_k]\n",
    "#     # [B, 1, d_k, N_p]\n",
    "\n",
    "#     X_pc = torch.matmul(X_ck, P_k.unsqueeze(1)) # [B, N_o, d_c, N_p]\n",
    "#     X_pc = X_pc.transpose(2, 3)  # [B, N_o, N_p, d_c]\n",
    "\n",
    "#     X_res = F.softmax(torch.matmul(X_pc, E_c.T), dim=-1) # [B, N_o, N_p, C]\n",
    "#     p_res = F.softmax(torch.matmul(P, E_c.T), dim=-1) # [B, N_p, C]\n",
    "\n",
    "#     # X_res holds O x P --> scores\n",
    "#     # p_res holds P --> scores\n",
    "\n",
    "#     return torch.prod((X_res * p_res.unsqueeze(1)).sum(dim=-1), dim=-1)\n",
    "\n",
    "# apply_predicate(X, predicate).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curriculum_vqa",
   "language": "python",
   "name": "curriculum_vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
