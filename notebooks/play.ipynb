{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "_include_('curriculum_vqa')\n",
    "_include_('commons')\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed);\n",
    "\n",
    "from cvqa import datasets, models, trainers, viz\n",
    "from commons import debug\n",
    "\n",
    "data_bin = f'{DEV_HOME}/curriculum_vqa/data-bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13f86e8e0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(2, 3)\n",
    "\n",
    "f = 1/np.log(x)\n",
    "\n",
    "\n",
    "plt.plot(x, np.exp(-f));\n",
    "plt.plot(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7576, 0.2793, 0.6387, 0.5247, 0.6826, 0.3051, 0.4635],\n",
       "        [0.4031, 0.7347, 0.4550, 0.5725, 0.4980, 0.9371, 0.6556],\n",
       "        [0.0293, 0.7999, 0.3138, 0.1980, 0.4162, 0.2843, 0.3398],\n",
       "        [0.3971, 0.7544, 0.5239, 0.7981, 0.7718, 0.0112, 0.8100],\n",
       "        [0.5695, 0.4388, 0.6397, 0.9743, 0.8300, 0.0444, 0.0246]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([\n",
    "    torch.rand(5, 2),\n",
    "    torch.rand(5, 5),\n",
    "], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5, 7)\n",
    "a[:,1:] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.zeros(5, dtype=torch.bool)\n",
    "mask[1] = 1\n",
    "mask[2] = 1\n",
    "a[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model Specification\n",
    "\n",
    "Concepts (red, block, triangle)\n",
    "* $c \\in [C]$ denotes a Concept Symbol\n",
    "* $v_c \\in \\mathbb R^{d_c}$ a concept vector\n",
    "* $E_c \\in \\mathbb R^{d_c \\times C}$ the concepts embedding matrix\n",
    "\n",
    "Concept Categories (shape, color)\n",
    "* $k \\in [K]$ denotes a Concept Category (color, shape)\n",
    "* $v_k \\in \\mathbb R^{d_k}$ a concept category vector\n",
    "* $E_k \\in \\mathbb R^{d_k \\times K}$ the concept categories embedding matrix\n",
    "\n",
    "Relations (contains, below, above)\n",
    "* $r \\in [R]$ denotes a relational concept Symbol\n",
    "* $v_r \\in \\mathbb R^{d_r}$ a concept vector\n",
    "* $E_r \\in \\mathbb R^{d_r \\times R}$ the relations embedding matrix\n",
    "\n",
    "\n",
    "\n",
    "Others\n",
    "* $o \\in \\mathbb R^{d_o}$ denotes a visual object.\n",
    "* $Q \\in \\mathbb R^{d_o \\times d_c \\times d_k}$ - The concept operators matrix.\n",
    "\n",
    "\n",
    "$ W_k = Q^\\top v_k $\n",
    "\n",
    "$k(o) = softmax(o^\\top W_k)$  // Gives the concept distribution for category k (eg color) of object o (eg the 3rd object in the scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "C = 100\n",
    "\n",
    "B = 32\n",
    "\n",
    "d = {\n",
    "    'B': 32,\n",
    "    \n",
    "    'o': 16,\n",
    "    'c': 40,\n",
    "    'k': 4,\n",
    "    'r': 25,\n",
    "    'ak': 29,\n",
    "    'av': 21,\n",
    "    \n",
    "    'w': 44,\n",
    "    'a': 45,\n",
    "    \n",
    "    'N_o': 7,\n",
    "    'N_p': 3\n",
    "}\n",
    "\n",
    "d_reversed = {v: k for k, v in d.items()}\n",
    "def shape(t):\n",
    "    return list(map(lambda dim: d_reversed.get(dim, dim), t.shape))\n",
    "    \n",
    "# shape(torch.rand(d['c'], d['o']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_c = torch.rand(C, d['c'])\n",
    "W_kc = torch.rand(d['k'], d['c'])\n",
    "\n",
    "C_ops = torch.rand(d['o'], d['c'], d['k'])\n",
    "Q_ops = torch.rand(d['o'], d['a'], d['k'])\n",
    "\n",
    "N_o = 7\n",
    "N_p = 3\n",
    "X = torch.rand(B, N_o, d['o'])\n",
    "X_weights_in_1 = torch.ones(d['B'], d['N_o'])\n",
    "X_weights_in_2 = torch.ones(d['B'], d['N_o'])\n",
    "X_weights_in = X_weights_in_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_op(op_seed, op_mat):\n",
    "    \"\"\"\n",
    "    op_seed: [B, d_op]\n",
    "    op_mat: [d_in, d_out, d_op]\n",
    "    \"\"\"\n",
    "    d_in, d_out, d_op = op_mat.shape\n",
    "    W = F.linear(op_seed, op_mat.reshape(-1, d_op))  # [B, d_out * d_in]\n",
    "    \n",
    "    return W.reshape(B, d_in, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_op = torch.rand(B, d['k'])\n",
    "\n",
    "# W_answer = get_op(question_op, Q_ops)  # [B, o, a]\n",
    "    \n",
    "# weighted_X = torch.matmul(X_weights_in.unsqueeze(1), X).squeeze()  # [B, o]\n",
    "\n",
    "# logits = torch.matmul(weighted_X.unsqueeze(1), W_answer)\n",
    "# shape(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_module(X, X_weights_in, question_op):\n",
    "    \"\"\"\n",
    "    X: [B, N_o, d_o]\n",
    "    X_weights_in: [B, N_o]\n",
    "    question_op: [B, d_k]\n",
    "    \"\"\"\n",
    "    W_answer = get_op(question_op, Q_ops)  # [o, a]\n",
    "    \n",
    "    weighted_X = torch.matmul(X_weights_in.unsqueeze(1), X).squeeze()  # [B, o]\n",
    "    \n",
    "    logits = torch.matmul(weighted_X.unsqueeze(1), W_answer)\n",
    "    return logits.squeeze()\n",
    "    \n",
    "shape(answer_module(X, X_weights_in_1, torch.rand(B, d['k'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'N_o']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1_module(X, X_weights_in, op):\n",
    "    \"\"\"\n",
    "    X: [B, N_o, d_o]\n",
    "    X_weights_in: [B, N_o]\n",
    "    op: [B, d_c]\n",
    "    \"\"\"\n",
    "    \n",
    "    #### Concept Category Predicate\n",
    "\n",
    "    # 1) op seed --> batch of concept ops\n",
    "    P = op  # P for predicate \n",
    "    P_k = F.linear(P, W_kc)  # [B, d_k] P_k for predicate category (eg color)\n",
    "    P_k = get_op(P_k, C_ops)  # [B, d_o, d_c]\n",
    "\n",
    "    # 2) Apply derived concept op to each object\n",
    "    X_c = torch.matmul(torch.rand(B, N_o, d['o']), P_k)  # [B, N_o, d_c]\n",
    "\n",
    "    # 3) Compute cosine similarity in concept distribution space (is there a better way to do this?)\n",
    "    X_c_probs = F.softmax(torch.matmul(X_c, E_c.T), dim=-1) # [B, N_o, C]\n",
    "    P_c_probs = F.softmax(torch.matmul(P, E_c.T), dim=-1) # [B, C]\n",
    "    XP_res = torch.sum(X_c_probs * P_c_probs.unsqueeze(1), dim=-1)  # [B, N_o], holds the probability every object passes the predicate\n",
    "\n",
    "    \n",
    "    #### Logical Not? Other Structures?\n",
    "    return X_weights_in * XP_res\n",
    "\n",
    "op1 = torch.rand(B, d['c'])\n",
    "f1_res = f1_module(X, X_weights_in_1, op1)\n",
    "shape(f1_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def attention(query, key, value, mask_weights=None, dropout=None):\n",
    "    \"\"\"\n",
    "    Copied and adjusted from the annotated transformer; https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask_weights is not None:\n",
    "        scores += mask_weights.unsqueeze(1).log()\n",
    "        \n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ops_q = torch.rand(d['o'], d['ak'], d['r'])\n",
    "A_ops_k = torch.rand(d['o'], d['ak'], d['r'])\n",
    "A_ops_v = torch.rand(d['o'], d['av'], d['r'])\n",
    "\n",
    "A_W_res = torch.rand(d['av'], 2)\n",
    "\n",
    "# rel_op = torch.rand(B, d['r'])\n",
    "# W_q = get_op(rel_op, A_ops_q)\n",
    "# W_k = get_op(rel_op, A_ops_k)\n",
    "# W_v = get_op(rel_op, A_ops_v)\n",
    "\n",
    "\n",
    "# Q = torch.matmul(X, W_q)\n",
    "# K = torch.matmul(X, W_k)\n",
    "# V = torch.matmul(X, W_v)\n",
    "\n",
    "# X_weights_in_1 = torch.ones(d['B'], d['N_o'])\n",
    "# X_weights_in_2 = torch.ones(d['B'], d['N_o'])\n",
    "\n",
    "# shape(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# att_res, p_att = attention(Q, K, V, X_weights_in_2)\n",
    "\n",
    "# shape(att_res)\n",
    "\n",
    "# res = F.softmax(F.linear(att_res, A_W_res.T), dim=-1)\n",
    "# shape(res[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'N_o']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f2_module(X, X_weights_in_1, X_weights_in_2, rel_op):\n",
    "    \"\"\"\n",
    "    X: [B, N_o, d_o]\n",
    "    X_weights_in_1, X_weights_in_2: [B, N_o]\n",
    "    rel_op: [B, d_r]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) op seed --> batch of attention parameters matrices\n",
    "    W_q = get_op(rel_op, A_ops_q)\n",
    "    W_k = get_op(rel_op, A_ops_k)\n",
    "    W_v = get_op(rel_op, A_ops_v)\n",
    "\n",
    "    Q = torch.matmul(X, W_q)\n",
    "    K = torch.matmul(X, W_k)\n",
    "    V = torch.matmul(X, W_v)\n",
    "    \n",
    "#     Q = Q * X_weights_in_1\n",
    "    \n",
    "    att_res, p_att = attention(Q, K, V, X_weights_in_2)\n",
    "    res = F.softmax(F.linear(att_res, A_W_res.T), dim=-1)\n",
    "    return res[:, :, 0] * X_weights_in_1\n",
    "\n",
    "\n",
    "\n",
    "rel_op = torch.rand(B, d['r'])\n",
    "\n",
    "f2_res = f2_module(X, X_weights_in_1, X_weights_in_2, rel_op)\n",
    "shape(f2_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate = torch.rand(B, N_p, d_c)\n",
    "\n",
    "\n",
    "# def apply_predicate(X, P):\n",
    "#     # objects concepts index\n",
    "#     X_ck = torch.matmul(X.unsqueeze(1), Q)  # [B, d_c, N_o, d_k]\n",
    "#     X_ck = X_ck.transpose(1, 2) # [B, N_o, d_c, d_k]\n",
    "\n",
    "#     # predicate to categories\n",
    "#     P_k = F.linear(P, W_kc)  # [B, N_p, d_k]\n",
    "#     P_k = P_k.transpose(1, 2)  # [B, d_k, N_p]\n",
    "\n",
    "#     # [B, N_o, d_c, d_k]\n",
    "#     # [B, 1, d_k, N_p]\n",
    "\n",
    "#     X_pc = torch.matmul(X_ck, P_k.unsqueeze(1)) # [B, N_o, d_c, N_p]\n",
    "#     X_pc = X_pc.transpose(2, 3)  # [B, N_o, N_p, d_c]\n",
    "\n",
    "#     X_res = F.softmax(torch.matmul(X_pc, E_c.T), dim=-1) # [B, N_o, N_p, C]\n",
    "#     p_res = F.softmax(torch.matmul(P, E_c.T), dim=-1) # [B, N_p, C]\n",
    "\n",
    "#     # X_res holds O x P --> scores\n",
    "#     # p_res holds P --> scores\n",
    "\n",
    "#     return torch.prod((X_res * p_res.unsqueeze(1)).sum(dim=-1), dim=-1)\n",
    "\n",
    "# apply_predicate(X, predicate).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define attributes and their values\n",
    "# to sample an object, sum a few descriptive tokens and scramble by a random transformation\n",
    "# sample a set of N objects\n",
    "# sample attention mask pattern\n",
    "# Questions:\n",
    "#     How many {P}\n",
    "#     Is there a {P}\n",
    "#     Is there no {P}\n",
    "#     What color/shape/etc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some word embeddings # 1h\n",
    "# Define attrs --> values # 1h\n",
    "# object sampler # 2h\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "from torchnlp.encoders.text import WhitespaceEncoder\n",
    "from torchnlp.word_to_vector import GloVe\n",
    "\n",
    "concept_dict = {\n",
    "    'shape': ['triangle', 'circle', 'square'],\n",
    "    'color': ['blue', 'brown', 'cyan', 'gray', 'green', 'purple', 'red', 'yellow'],\n",
    "    'material': ['metal', 'rubber']\n",
    "}\n",
    "\n",
    "concept_keys = list(concept_dict.keys())\n",
    "concept_values = list(itertools.chain(*concept_dict.values()))\n",
    "\n",
    "\n",
    "encoder = WhitespaceEncoder(concept_keys + concept_values)\n",
    "vocab_set = set(encoder.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:02<00:00, 149225.72it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrained_embedding = GloVe(name='6B', dim=100, is_include=lambda w: w in vocab_set)\n",
    "embedding_weights = torch.Tensor(encoder.vocab_size, pretrained_embedding.dim)\n",
    "for i, token in enumerate(encoder.vocab):\n",
    "    embedding_weights[i] = pretrained_embedding[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute a good representation, we want all attributes to be easily queryable;\n",
    "\n",
    "# X[K, d] -> W_enc -> x_vec[o] -> W_dec -> [K, N_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.choice(concept_dict['shape'])\n",
    "encoder.encode('circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "objects = []\n",
    "for i in range(N):\n",
    "    obj = []\n",
    "    for ck in concept_dict:\n",
    "        cv = random.choice(concept_dict[ck])\n",
    "        c_id = encoder.encode(cv)\n",
    "        obj.append(c_id)\n",
    "    objects.append(torch.cat(obj))\n",
    "    \n",
    "y = torch.stack(objects)\n",
    "X = embedding_weights[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = torch.utils.data.TensorDataset(X, y)\n",
    "for e in range(10):\n",
    "    for i, s in torch.utils.data.DataLoader(ds, batch_size=32, shuffle=True):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \n",
    "torch.nn.Sequential(\n",
    "    nn.Linear()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curriculum_vqa",
   "language": "python",
   "name": "curriculum_vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
